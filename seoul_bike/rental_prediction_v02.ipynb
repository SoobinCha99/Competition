{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 패키지 로드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\Anaconda3\\envs\\main\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor  \n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor \n",
    "from sklearn.model_selection import GridSearchCV \n",
    "random_state = 42 \n",
    "\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "test_answer = pd.read_csv('./data/test_answer.csv',thousands=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train preprocess\n",
    "\n",
    "#split y/m/d\n",
    "year = []\n",
    "month = []\n",
    "day = [] \n",
    "\n",
    "for date in train[\"date\"] :\n",
    "    y = date.split('-')[0]\n",
    "    m = date.split('-')[1]\n",
    "    d = date.split('-')[2]\n",
    "    \n",
    "    year.append(int(y))\n",
    "    month.append(int(m))\n",
    "    day.append(int(d))\n",
    "\n",
    "train[\"year\"] = year \n",
    "train[\"month\"] = month \n",
    "train[\"day\"] = day\n",
    "\n",
    "#fill na \n",
    "train[\"precipitation\"] = train[\"precipitation\"].replace(np.nan, 0)\n",
    "train[\"PM10\"] = train[\"PM10\"].fillna(method=\"ffill\")\n",
    "train[\"PM2.5\"] = train[\"PM2.5\"].fillna(method=\"ffill\")\n",
    "train[\"sunshine_sum\"] = train[\"sunshine_sum\"].fillna(method=\"ffill\")\n",
    "\n",
    "\n",
    "#test preprocess\n",
    "\n",
    "#split y/m/d\n",
    "year_ =[] \n",
    "month_ = []\n",
    "day_= [] \n",
    "\n",
    "for date in test[\"date\"]:\n",
    "    y_ = date.split(\"-\")[0]\n",
    "    m_ = date.split(\"-\")[1]\n",
    "    d_ = date.split(\"-\")[2]\n",
    "\n",
    "    year_.append(int(y_))\n",
    "    month_.append(int(m_))\n",
    "    day_.append(int(m_))\n",
    "\n",
    "test[\"year\"] = year_\n",
    "test[\"month\"] = month_\n",
    "test[\"day\"] = day_ \n",
    "\n",
    "#fill na\n",
    "test[\"precipitation\"] = test[\"precipitation\"].replace(np.nan, 0)\n",
    "test[\"PM10\"] = test[\"PM10\"].fillna(method=\"ffill\")\n",
    "test[\"PM2.5\"] = test[\"PM2.5\"].fillna(method=\"ffill\")\n",
    "test[\"sunshine_sum\"] = test[\"sunshine_sum\"].fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 특성 공학 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#불쾌지수 특성 생성 \n",
    "\n",
    "def get_discomfort(temp_mean, humidity):\n",
    "    temp = temp_mean\n",
    "    humidity = humidity / 100\n",
    "    \n",
    "    discomfort = 1.8 * temp - 0.55 * (1 - humidity) * (1.8*temp - 26) + 32\n",
    "    return discomfort\n",
    "\n",
    "train['discomfort'] = [0] * len(train)\n",
    "for i in range(len(train)):\n",
    "    train.discomfort[i] = get_discomfort(train.humidity[i], \n",
    "                                            train.temp_mean[i])\n",
    "\n",
    "test['discomfort'] = [0] * len(test)\n",
    "for i in range(len(test)):\n",
    "    test.discomfort[i] = get_discomfort(test.humidity[i], \n",
    "                                           test.temp_mean[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일교차 특성 생성 \n",
    "\n",
    "train['temp_diff'] = train['temp_highest'] - train['temp_lowest'] \n",
    "test['temp_diff'] = test['temp_highest'] - test['temp_lowest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# 채감온도 특성 생성 \\ndef get_sense_temp(temp_mean, wind_mean): \\n    sense_temp = 13.12 + (0.6215 * temp_mean) - (11.37 * wind_mean *0.16) + (0.3965 * wind_mean * temp_mean * 0.16)\\n    return sense_temp\\n\\ntrain['sense_temp'] = [0] * len(train)\\nfor i in range(len(train)):\\n    train.discomfort[i] = get_sense_temp(train.temp_mean[i], \\n                                            train.wind_mean[i])\\n\\ntest['sense_temp'] = [0] * len(test)\\nfor i in range(len(test)):\\n    test.discomfort[i] = get_sense_temp(test.temp_mean[i], \\n                                            test.wind_mean[i])\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 채감온도 특성 생성 \n",
    "def get_sense_temp(temp_mean, wind_mean): \n",
    "    sense_temp = 13.12 + (0.6215 * temp_mean) - (11.37 * wind_mean *0.16) + (0.3965 * wind_mean * temp_mean * 0.16)\n",
    "    return sense_temp\n",
    "\n",
    "train['sense_temp'] = [0] * len(train)\n",
    "for i in range(len(train)):\n",
    "    train.discomfort[i] = get_sense_temp(train.temp_mean[i], \n",
    "                                            train.wind_mean[i])\n",
    "\n",
    "test['sense_temp'] = [0] * len(test)\n",
    "for i in range(len(test)):\n",
    "    test.discomfort[i] = get_sense_temp(test.temp_mean[i], \n",
    "                                            test.wind_mean[i])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추위 특성 생성 \n",
    "train[\"coldness\"] = train[\"temp_lowest\"] / train[\"wind_mean\"]\n",
    "test[\"coldness\"] = test[\"temp_lowest\"] / test[\"wind_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create final data \n",
    "train_x = train.drop([\"date\", \"rental\"],axis=1)\n",
    "train_y = train[\"rental\"]\n",
    "\n",
    "test_x = test.drop([\"date\"],axis=1)\n",
    "test_y = test_answer[\"rental\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric\n",
    "def NMAE(true, pred):\n",
    "    score = np.mean(np.abs(true-pred) / true)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8836727252111978\n",
      "1.2429259327402773\n",
      "1.3522322697892684\n"
     ]
    }
   ],
   "source": [
    "#trend 반영\n",
    "reg_2018 = sum(train.loc[train['year'] == 2018, 'rental'].values)\n",
    "reg_2019 = sum(train.loc[train['year'] == 2019, 'rental'].values)\n",
    "reg_2020 = sum(train.loc[train['year'] == 2020, 'rental'].values)\n",
    "reg_2021 = sum(test_answer.rental.values)\n",
    "\n",
    "print(reg_2019/reg_2018)\n",
    "print(reg_2020/reg_2019)\n",
    "print(reg_2021/reg_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgr :  0.35125932041984953\n",
      "rf :  0.34369636951838767\n",
      "gbr :  0.3172690376243056\n",
      "mlp :  0.45560816419796757\n",
      "ensmble :  0.21277800939097297\n"
     ]
    }
   ],
   "source": [
    "xgr = XGBRegressor(random_state=random_state) \n",
    "xgr.fit(train_x, train_y)\n",
    "\n",
    "rf = RandomForestRegressor(random_state=random_state) \n",
    "rf.fit(train_x,train_y)\n",
    "\n",
    "gbr = GradientBoostingRegressor(random_state=random_state) \n",
    "gbr.fit(train_x,train_y)\n",
    "\n",
    "mlp = MLPRegressor(max_iter=5000, random_state=random_state)\n",
    "mlp.fit(train_x, train_y)\n",
    "\n",
    "xgr_pred = xgr.predict(test_x)\n",
    "rf_pred = rf.predict(test_x) \n",
    "gbr_pred = gbr.predict(test_x)\n",
    "mlp_pred = mlp.predict(test_x)\n",
    "\n",
    "ensemble_pred = (xgr_pred + rf_pred + gbr_pred + mlp_pred) / 4\n",
    "ensemble_pred = ensemble_pred * 1.35 #trend 반영 \n",
    "\n",
    "print(\"xgr : \", NMAE(test_y, xgr_pred))\n",
    "print(\"rf : \",NMAE(test_y, rf_pred))\n",
    "print(\"gbr : \",NMAE(test_y, gbr_pred))\n",
    "print(\"mlp : \",NMAE(test_y, mlp_pred))\n",
    "print(\"ensmble : \",NMAE(test_y, ensemble_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>rental</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>26321.987432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>26029.925138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>23582.676737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>26872.360295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>24742.437912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>36301.357341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>34639.068487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>54404.385682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>40451.648119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>37551.654580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date        rental\n",
       "0    2021-01-01  26321.987432\n",
       "1    2021-01-02  26029.925138\n",
       "2    2021-01-03  23582.676737\n",
       "3    2021-01-04  26872.360295\n",
       "4    2021-01-05  24742.437912\n",
       "..          ...           ...\n",
       "360  2021-12-27  36301.357341\n",
       "361  2021-12-28  34639.068487\n",
       "362  2021-12-29  54404.385682\n",
       "363  2021-12-30  40451.648119\n",
       "364  2021-12-31  37551.654580\n",
       "\n",
       "[365 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv('./data/sample_submission.csv')\n",
    "sample_submission[\"rental\"] = ensemble_pred \n",
    "\n",
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('rental_prediction_v02.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model \n",
    "with girdsearchcv optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearchCV(models,params, x, y): \n",
    "    best_models =[] \n",
    "    for i in tqdm(range(0,len(models))):\n",
    "        model_gird = GridSearchCV(models[i], params[i], n_jobs = 4, cv=5)\n",
    "        model_gird.fit(x,y)\n",
    "        best_models.append(model_gird.best_estimator_)\n",
    "    \n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "xgr = XGBRegressor()\n",
    "models.append(xgr)\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "models.append(rf)\n",
    "\n",
    "gbr = GradientBoostingRegressor() \n",
    "models.append(gbr)\n",
    "\n",
    "mlp = MLPRegressor() \n",
    "models.append(mlp)\n",
    "\n",
    "params = []\n",
    "\n",
    "params_xgr = { \n",
    "    'max_depth' : [3,4,5,6,7,8,9,10]\n",
    "}\n",
    "params.append(params_xgr)\n",
    "\n",
    "params_rf = {\n",
    "    'n_estimators' : [70,80,90,100,110,120,130],\n",
    "    'min_samples_split': [1,2,3,4,5,6,7,8]\n",
    "}\n",
    "params.append(params_rf)\n",
    "\n",
    "params_gbr = {\n",
    "    'learning_rate' : [0.07, 0.08, 0.09, 0.1, 1.1, 1.2],\n",
    "    'n_estimators' : [70,80,90,100,110,120,130]\n",
    "}\n",
    "params.append(params_gbr)\n",
    "\n",
    "params_mlp ={ \n",
    "    'max_iter' : [500,1000,1500,2000,2500,3000]\n",
    "}\n",
    "params.append(params_mlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [02:03<00:00, 30.77s/it]\n"
     ]
    }
   ],
   "source": [
    "best_models = gridSearchCV(models,params,train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "             gamma=0, gpu_id=-1, importance_type=None,\n",
      "             interaction_constraints='', learning_rate=0.300000012,\n",
      "             max_delta_step=0, max_depth=3, min_child_weight=1, missing=nan,\n",
      "             monotone_constraints='()', n_estimators=100, n_jobs=32,\n",
      "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
      "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
      "             validate_parameters=1, verbosity=None)\n",
      "RandomForestRegressor(n_estimators=70)\n",
      "GradientBoostingRegressor(learning_rate=0.09, n_estimators=130)\n",
      "MLPRegressor(max_iter=2000)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(models)):\n",
    "    print(best_models[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgr :  0.32619025055284\n",
      "rf :  0.34068654793399966\n",
      "gbr :  0.32564108967282596\n",
      "mlp :  0.47474614956773087\n",
      "ensmble :  0.3343358463421674\n"
     ]
    }
   ],
   "source": [
    "for model in best_models:\n",
    "    model.fit(train_x, train_y)\n",
    "    \n",
    "predictions = [] \n",
    "for model in best_models:\n",
    "    pred = model.predict(test_x)\n",
    "    predictions.append(pred)\n",
    "\n",
    "ensemble_pred = (predictions[0] + predictions[1] + predictions[2] + predictions[3]) / 4\n",
    "\n",
    "print(\"xgr : \", NMAE(test_y, predictions[0]))\n",
    "print(\"rf : \",NMAE(test_y, predictions[1]))\n",
    "print(\"gbr : \",NMAE(test_y, predictions[2]))\n",
    "print(\"mlp : \",NMAE(test_y, predictions[3]))\n",
    "print(\"ensmble : \",NMAE(test_y, ensemble_pred))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b98918487499e9eace60228dcc2a616d39dc470c6c38c5f5762d388d3648139d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('main')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
